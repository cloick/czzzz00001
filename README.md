# 1. PRÉSENTATION DE LA MISSION

## 1.1 Contexte et objectifs de l'alternance

Mon alternance au sein du Crédit Agricole Group Infrastructure Platform (CA-GIP) a débuté en septembre 2022, dans le cadre de ma formation d'ingénieur à 3iL Ingénieurs Limoges. Cette opportunité s'inscrivait dans une démarche de spécialisation en sciences des données et intelligence artificielle, domaines en pleine expansion dans le secteur bancaire.

Le contexte économique et technologique de ces dernières années a placé la transformation numérique au cœur des enjeux stratégiques des institutions financières. Le Crédit Agricole, conscient de ces défis, a engagé une démarche d'innovation technologique visant à optimiser ses processus internes et à améliorer la qualité de service. C'est dans cette dynamique que s'inscrit ma mission d'alternance, avec pour objectif de contribuer à l'émergence d'une culture data-driven au sein de l'organisation.

Les objectifs initiaux de cette alternance étaient multiples :
- **Objectif technique** : Développer des compétences approfondies en data science et intelligence artificielle dans un contexte professionnel exigeant
- **Objectif métier** : Comprendre les enjeux spécifiques du secteur bancaire et les contraintes réglementaires associées
- **Objectif personnel** : Acquérir une vision globale des défis de transformation numérique dans une organisation de grande envergure
- **Objectif d'innovation** : Contribuer à l'introduction et au développement de nouvelles approches technologiques au sein de l'équipe

Cette alternance représentait également pour moi une opportunité unique d'évoluer dans un environnement où la dimension technique se conjugue avec des enjeux organisationnels complexes, particulièrement dans le cadre de l'adoption de nouvelles technologies dans un contexte traditionnel.

## 1.2 Missions confiées et évolution du périmètre

### Missions initiales (Septembre 2022 - Février 2023)

À mon arrivée, mes missions étaient centrées sur le capacity planning et l'analyse de données. L'objectif principal était de développer une expertise en modélisation prédictive pour optimiser la gestion des ressources informatiques. Cette première phase incluait :

- Analyse des données de performance des systèmes existants
- État de l'art des modèles de prévision de séries temporelles (ARIMA, SARIMA, LSTM)
- Développement de tableaux de bord pour le suivi des métriques métiers et techniques
- Conception d'une architecture MLOps pour automatiser les processus de prévision

### Évolution progressive du périmètre (Mars 2023 - Septembre 2023)

Face aux premiers résultats prometteurs et à l'intérêt suscité par les approches d'intelligence artificielle, mon périmètre d'action s'est progressivement élargi. Cette évolution s'est matérialisée par :

- **Extension aux problématiques de classification** : Développement de modèles NLP pour l'analyse automatisée des tickets incidents (ServiceNow/Métis)
- **Diversification des techniques** : Intégration de modèles de clustering pour la détermination de root causes
- **Montée en responsabilités** : Pilotage de projets de bout en bout, de la conception à la mise en production
- **Dimension transverse** : Participation à des projets impactant plusieurs équipes du cluster BPCR

### Élargissement stratégique (Octobre 2023 - Présent)

La reconnaissance de l'apport de l'intelligence artificielle au sein de l'équipe a conduit à une expansion significative de mes responsabilités :

- **Rôle d'expert technique** : Conseil et accompagnement d'autres équipes dans l'adoption de solutions IA
- **Projets stratégiques** : Participation à la solution AppOps 360 pour une vision transverse des enjeux du cluster
- **Innovation technologique** : Exploration et implémentation de l'IA générative et des Large Language Models (LLM)
- **Acculturation organisationnelle** : Formation et sensibilisation des équipes aux enjeux de la data science

Cette évolution du périmètre reflète une transformation progressive du rôle : d'un profil technique spécialisé vers un rôle de catalyseur de l'innovation IA au sein de l'organisation. Cette trajectoire illustre parfaitement les défis et opportunités liés à l'introduction de l'intelligence artificielle dans un environnement traditionnel.

## 1.3 Méthode de travail et organisation

### Approche méthodologique

Mon approche de travail s'articule autour des principes de l'agilité et du DevOps, adaptés aux spécificités des projets de data science et d'intelligence artificielle. Cette méthode hybride, que l'on peut qualifier de "MLOps", intègre :

**Méthodologie Agile (Scrum)** :
- Sprints de 2 semaines avec des objectifs clairs et mesurables
- Rétrospectives régulières pour l'amélioration continue
- Collaboration étroite avec les équipes métiers pour garantir l'alignement business
- Démonstrations fréquentes des résultats pour maintenir l'engagement des parties prenantes

**Pratiques DevOps adaptées au ML** :
- Versioning systématique du code et des modèles (Git, MLflow)
- Intégration continue avec tests automatisés (GitLab CI/CD)
- Déploiement progressif des modèles (blue/green deployment)
- Monitoring continu des performances en production

### Organisation du travail

**Planification et priorisation** :
La gestion des multiples projets nécessite une organisation rigoureuse. J'utilise une approche matricielle pour équilibrer :
- Les projets à court terme (maintenance, optimisations)
- Les projets à moyen terme (nouveaux modèles, évolutions)
- Les projets exploratoires (veille technologique, prototypage)

**Collaboration et communication** :
- Points hebdomadaires avec mon maître d'apprentissage pour le suivi des projets
- Présentations mensuelles aux équipes pour partager les avancées
- Documentation systématique des solutions développées
- Formation et accompagnement des collègues sur les outils et méthodes

**Gestion de la qualité** :
- Revues de code systématiques avant mise en production
- Tests de régression pour garantir la stabilité des modèles
- Backtesting régulier pour valider les performances
- Respect des standards de sécurité et de conformité du Crédit Agricole

### Outils et environnement technique

Mon environnement de travail s'appuie sur un stack technologique moderne et évolutif :

**Développement** : Python (FastAPI, Pandas, Scikit-learn, TensorFlow), SQL, JavaScript
**Orchestration** : Apache Airflow, Kubernetes, Docker
**Monitoring** : MLflow, Grafana, Elasticsearch
**Collaboration** : GitLab, Confluence, Slack
**Visualisation** : Power BI, Matplotlib, Streamlit

Cette organisation méthodologique et technique a permis de maintenir un niveau de qualité élevé tout en favorisant l'innovation et l'expérimentation. Elle constitue également un modèle transférable pour d'autres équipes souhaitant adopter des pratiques similaires.

L'évolution de mes méthodes de travail au fil de l'alternance témoigne d'une adaptation constante aux besoins de l'organisation et aux spécificités des projets d'intelligence artificielle dans un contexte d'entreprise traditionnelle.

_________________________________________________________________________

# 3. DÉROULEMENT CHRONOLOGIQUE DE LA MISSION

## 3.1 Phase 1 : Diagnostic et prise en main (Septembre - Décembre 2022)

### 3.1.1 Objectifs prévus et réalisations

**Objectifs initiaux** :
À mon arrivée, les objectifs fixés étaient volontairement limités pour permettre une montée en compétences progressive. Il était prévu que je me concentre sur :
- La prise en main de l'environnement technique et des outils du Crédit Agricole
- L'analyse des données existantes pour le capacity planning
- Un premier état de l'art des modèles de prévision de séries temporelles
- La conception de tableaux de bord basiques pour le suivi des métriques

**Réalisations effectives** :
Cette phase s'est révélée plus riche que prévu. Au-delà des objectifs fixés, j'ai pu :
- Effectuer un diagnostic approfondi de la maturité technique de l'équipe en matière d'IA
- Identifier des opportunités d'amélioration dans les processus existants
- Réaliser un benchmark comparatif détaillé des modèles ARIMA, SARIMA et LSTM
- Développer mes premiers prototypes de modèles prédictifs
- Établir des premiers contacts avec d'autres équipes du cluster BPCR

**Écarts et enseignements** :
L'écart principal résidait dans la découverte d'un terreau plus fertile que prévu pour l'innovation IA. Contrairement aux craintes initiales d'une résistance organisationnelle, j'ai trouvé une réelle curiosité et une ouverture aux nouvelles approches technologiques. Cette période m'a également permis de comprendre que les besoins dépassaient largement le seul capacity planning.

### 3.1.2 Défis rencontrés et adaptations

**Défis techniques** :
- Accès aux données : Les systèmes d'information du Crédit Agricole étant complexes, l'accès aux données s'est avéré plus long que prévu
- Contraintes sécuritaires : Adaptation aux protocoles de sécurité stricts du secteur bancaire
- Hétérogénéité des sources : Nécessité de comprendre et d'harmoniser des données provenant de multiples référentiels

**Adaptations réalisées** :
- Développement d'un réseau de contacts internes pour faciliter l'accès aux données
- Formation accélérée sur les outils et procédures internes
- Mise en place d'une méthodologie de documentation rigoureuse pour faciliter les transferts de connaissances

## 3.2 Phase 2 : Montée en compétences et projets pilotes (Janvier - Août 2023)

### 3.2.1 Expansion du périmètre d'action

**Objectifs redéfinis** :
Suite aux premiers résultats encourageants, une redéfinition des objectifs s'est opérée en janvier 2023 :
- Industrialisation de la pipeline MLOps pour le capacity planning
- Extension aux problématiques de classification de texte (tickets incidents)
- Déploiement de solutions en production avec monitoring
- Initiation à l'accompagnement d'autres équipes

**Réalisations dépassant les attentes** :
- **Pipeline MLOps complète** : Développement d'une architecture end-to-end intégrant Docker, FastAPI, et TensorFlow LSTM avec monitoring temps réel
- **Solutions NLP avancées** : Implémentation de modèles de classification zero-shot et fine-tuning pour l'analyse des tickets Métis
- **Clustering pour root cause** : Développement d'algorithmes de clustering pour identifier automatiquement les causes racines d'incidents
- **Déploiement Kubernetes** : Mise en production de solutions containerisées avec orchestration ArgoCD

**Impact organisationnel inattendu** :
Cette phase a révélé un appétit organisationnel fort pour l'IA. Les démonstrations régulières ont suscité des demandes d'autres équipes, transformant progressivement mon rôle d'exécutant technique vers celui de consultant interne.

### 3.2.2 Évolution des méthodes de travail

**Transition vers l'autonomie** :
- Passage d'une supervision rapprochée à une gestion par objectifs
- Prise d'initiatives dans la proposition de nouveaux projets
- Développement d'une approche proactive dans l'identification des besoins

**Première expérience de formation** :
- Animation de sessions de sensibilisation aux enjeux de l'IA
- Rédaction de documentation technique accessible aux non-spécialistes
- Accompagnement d'autres développeurs dans l'adoption des outils MLOps

## 3.3 Phase 3 : Industrialisation et déploiement (Septembre 2023 - Présent)

### 3.3.1 Transformation du rôle et des responsabilités

**Objectifs ambitieux** :
Cette phase marque une évolution majeure avec des objectifs élargis :
- Pilotage de projets transverses (AppOps 360)
- Rôle d'expert technique pour l'ensemble du cluster BPCR
- Exploration de l'IA générative et des LLM
- Contribution à la stratégie d'adoption de l'IA

**Réalisations stratégiques** :
- **Solution AppOps 360** : Conception et déploiement d'une solution data-driven pour une vision à 360° des enjeux transverses du cluster
- **Refonte outillage obsolescence** : Participation à la modernisation des outils de gestion de l'obsolescence technique avec conception d'un datawarehouse SQL et d'interfaces Power BI
- **IA générative** : Implémentation de solutions basées sur les LLM pour l'analyse de documents techniques et verbatims
- **Dashboards stratégiques** : Développement de tableaux de bord remontant aux comités directoriaux

### 3.3.2 Acculturation et transfert de connaissances

**Évolution non planifiée mais structurante** :
Ce qui n'était pas prévu initialement est devenu central : mon rôle d'évangélisation et d'acculturation aux technologies IA.

**Activités d'accompagnement** :
- Formation d'autres équipes aux outils et méthodologies data science
- Rédaction de guides et documentation technique
- Conseil et support dans l'adoption de solutions IA
- Participation aux décisions d'investissement technologique (commande de serveurs, outils)

**Impact organisationnel mesuré** :
- Augmentation du nombre d'équipes utilisant des solutions IA
- Montée en compétences générale observée sur les sujets data
- Évolution des processus de travail intégrant les approches data-driven

### 3.3.3 Consolidation et perspectives

**Bilan de la phase actuelle** :
Cette phase confirme la transformation du périmètre initial. D'un rôle technique spécialisé, j'ai évolué vers un rôle hybride combinant :
- Expertise technique de haut niveau
- Capacité d'accompagnement organisationnel
- Vision stratégique sur l'adoption de l'IA

**Écarts significatifs par rapport aux prévisions initiales** :
- **Ampleur du périmètre** : Passage de projets individuels à des enjeux transverses
- **Dimension organisationnelle** : Intégration d'une composante de transformation culturelle non anticipée
- **Reconnaissance institutionnelle** : Participation aux réflexions stratégiques du cluster

**Facteurs explicatifs des écarts** :
- Contexte organisationnel favorable à l'innovation
- Résultats techniques probants ayant suscité l'intérêt
- Capacité d'adaptation et de montée en compétences
- Besoin organisationnel latent révélé par les premiers succès

## 3.4 Analyse transversale du déroulement

### 3.4.1 Constantes observées

**Accélération progressive** : Chaque phase a été marquée par une accélération du rythme et une complexification des enjeux.

**Effet de levier** : Les succès techniques ont systématiquement généré de nouvelles opportunités organisationnelles.

**Apprentissage continu** : La nécessité de s'adapter en permanence aux évolutions technologiques et organisationnelles.

### 3.4.2 Facteurs clés de succès

**Agilité et adaptation** : Capacité à faire évoluer les objectifs en fonction des opportunités
**Approche collaborative** : Intégration systématique des retours des équipes métiers
**Documentation et transfert** : Effort constant de capitalisation des connaissances
**Vision long terme** : Équilibre entre résultats immédiats et construction d'une expertise durable

Cette évolution chronologique illustre parfaitement la transformation progressive d'un environnement traditionnel vers l'adoption de l'intelligence artificielle, thème central de la réflexion développée dans la seconde partie de ce mémoire.



___________________________________________________________________________________________________

# 4. DESCRIPTION DES PROJETS RÉALISÉS

## 4.1 Pipeline MLOps pour le capacity planning

### 4.1.1 Contexte métier et problématique

Le capacity planning représente un enjeu stratégique majeur pour le Crédit Agricole Group Infrastructure Platform. La capacité à anticiper les besoins en ressources informatiques conditionne directement la qualité de service et l'optimisation des coûts d'infrastructure. Avant mon intervention, cette activité reposait principalement sur des analyses manuelles et des extrapolations empiriques, générant des risques de sur-dimensionnement ou de sous-dimensionnement des ressources.

La problématique centrale consistait à développer un système de prévision automatisé capable d'analyser les tendances historiques des métriques techniques (PUC, SFTN, API) et métiers (MaBanque, NPC) pour générer des prévisions fiables à différents horizons temporels (1 semaine, 1 mois, 3 mois).

### 4.1.2 Architecture technique et choix technologiques

**Architecture globale** :
L'architecture développée suit les principes MLOps pour garantir la reproductibilité, la traçabilité et la maintenabilité de la solution. Elle s'articule autour de plusieurs composants :

- **Couche d'ingestion** : Connecteurs vers les référentiels de données (bases Oracle, API REST)
- **Couche de traitement** : Pipeline de préparation des données utilisant Pandas et Scikit-learn
- **Couche de modélisation** : Modèles de prévision implémentés avec TensorFlow
- **Couche de service** : API REST développée avec FastAPI pour servir les prédictions
- **Couche de monitoring** : Système de surveillance des performances et de détection de dérive

**Technologies utilisées** :
- **Conteneurisation** : Docker pour l'isolation et la portabilité
- **Orchestration** : Apache Airflow pour l'automatisation des pipelines
- **Stockage** : Elasticsearch pour l'indexation des données temporelles
- **API** : FastAPI pour l'exposition des services de prédiction
- **Monitoring** : MLflow pour le tracking des expériences et des modèles
- **Déploiement** : Kubernetes avec ArgoCD pour le déploiement continu

### 4.1.3 Modèles de prévision de séries temporelles

**Benchmark des approches** :
Une étude comparative approfondie a été menée entre plusieurs familles de modèles :

- **Modèles statistiques classiques** : ARIMA et SARIMA pour capturer les tendances et saisonnalités
- **Modèles de deep learning** : LSTM (Long Short-Term Memory) pour apprendre les patterns complexes
- **Modèles hybrides** : Combinaison des approches pour optimiser les performances

**Choix techniques justifiés** :
L'architecture finale intègre une approche hybride permettant de sélectionner automatiquement le modèle le plus adapté selon les caractéristiques des données :
- SARIMA pour les séries avec forte composante saisonnière
- LSTM pour les séries avec patterns complexes et non-linéaires
- Ensemble methods pour améliorer la robustesse des prédictions

### 4.1.4 Résultats et impact

**Performances obtenues** :
- Réduction de 30% de l'erreur de prévision par rapport à l'approche manuelle
- Automatisation de 80% des tâches de capacity planning
- Génération de prévisions à J+7, J+30 et J+90 avec intervalles de confiance

**Impact organisationnel** :
- Libération de temps pour les équipes techniques (focus sur l'analyse plutôt que la collecte)
- Amélioration de la prise de décision grâce à des prévisions quantifiées
- Réduction des risques de sur-dimensionnement des infrastructures

## 4.2 Modèles NLP pour l'analyse de verbatims clients

### 4.2.1 Contexte et enjeux métiers

L'analyse des retours clients constitue un pilier de la stratégie d'amélioration continue du Crédit Agricole. Les enquêtes IRC Flash génèrent quotidiennement des milliers de verbatims qu'il était nécessaire d'analyser manuellement pour identifier les problèmes récurrents et les axes d'amélioration. Cette approche présentait plusieurs limites : temps de traitement important, subjectivité de l'analyse, et risque de perte d'information.

L'objectif était de développer un système automatisé capable d'analyser les verbatims pour :
- Identifier automatiquement les sujets récurrents
- Classer les retours selon leur niveau de satisfaction
- Extraire les problèmes prioritaires nécessitant une action corrective
- Fournir des insights actionnables aux équipes métiers

### 4.2.2 Architecture NLP et techniques utilisées

**Pipeline de traitement** :
Le système développé intègre une chaîne de traitement NLP complète :

1. **Préparation des données** : Nettoyage, tokenisation, normalisation des textes
2. **Extraction de features** : TF-IDF, embeddings pré-entraînés, features linguistiques
3. **Modélisation** : Modèles de classification et clustering
4. **Post-traitement** : Agrégation des résultats et génération de rapports

**Techniques de classification** :
- **Zero-shot classification** : Utilisation de modèles pré-entraînés pour classifier sans données d'apprentissage spécifiques
- **Fine-tuning** : Adaptation de modèles BERT/RoBERTa sur les données spécifiques du Crédit Agricole
- **Ensemble methods** : Combinaison de plusieurs approches pour améliorer la robustesse

**Clustering et topic modeling** :
- **Topic Modeling** : Techniques LDA et BERTopic pour identifier les thèmes récurrents
- **Clustering hiérarchique** : Regroupement des verbatims similaires
- **Visualisation** : Représentation graphique des clusters pour faciliter l'interprétation

### 4.2.3 Évolution vers l'IA générative

**Intégration des LLM** :
L'évolution technologique a permis d'intégrer des Large Language Models pour enrichir l'analyse :
- **Résumé automatique** : Génération de synthèses des verbatims par catégorie
- **Extraction d'entités** : Identification automatique des produits, services, et problèmes mentionnés
- **Génération de recommandations** : Suggestions d'actions correctives basées sur l'analyse

**Technologies utilisées** :
- **Frameworks** : Hugging Face Transformers, LangChain
- **Modèles** : BERT, RoBERTa, GPT pour différents cas d'usage
- **Infrastructure** : Déploiement sur GPU avec optimisation des performances

### 4.2.4 Résultats et valeur ajoutée

**Gains quantifiés** :
- Réduction de 70% du temps d'analyse des verbatims
- Identification automatique de 95% des problèmes récurrents
- Génération de rapports d'analyse en temps réel

**Impact métier** :
- Amélioration de la réactivité face aux problèmes clients
- Identification proactive de nouveaux enjeux de satisfaction
- Aide à la décision basée sur des données quantifiées

## 4.3 Classification et clustering pour la fiabilisation des tickets

### 4.3.1 Problématique des tickets incidents

La gestion des incidents informatiques via l'outil ServiceNow (Métis) représente un volume considérable de données textuelles non structurées. L'analyse manuelle de ces tickets pour identifier les causes racines et optimiser les processus de résolution était chronophage et sujette à des variations d'interprétation.

L'objectif était de développer un système intelligent capable de :
- Classifier automatiquement les tickets selon leur nature et leur criticité
- Identifier les causes racines des incidents récurrents
- Optimiser la répartition des tickets vers les équipes spécialisées
- Détecter les patterns d'incidents pour anticiper les problèmes

### 4.3.2 Architecture technique et déploiement

**Pipeline de traitement** :
La solution développée s'appuie sur une architecture moderne intégrant :

- **Ingestion** : Connexion à l'API ServiceNow pour récupération des tickets
- **Préprocessing** : Nettoyage et normalisation des données textuelles
- **Modélisation** : Modèles de classification et clustering en parallèle
- **Déploiement** : Containerisation et orchestration Kubernetes
- **Monitoring** : Suivi des performances et détection de dérive

**Technologies de déploiement** :
- **Orchestration** : Apache Airflow pour l'automatisation des pipelines
- **Conteneurisation** : Docker avec images optimisées
- **Déploiement** : Kubernetes avec ArgoCD pour la gestion des versions
- **Monitoring** : MLflow pour le tracking, Grafana pour la visualisation
- **Gestion des dépendances** : Poetry pour la reproductibilité

### 4.3.3 Modèles de classification avancés

**Approches de classification** :
- **Classification supervisée** : Modèles entraînés sur des données historiques étiquetées
- **Zero-shot classification** : Utilisation de modèles pré-entraînés pour des catégories non vues
- **Classification hiérarchique** : Modèles à plusieurs niveaux pour affiner la catégorisation

**Techniques de clustering** :
- **Clustering par similarité** : Regroupement des tickets similaires pour identifier les patterns
- **Clustering temporel** : Analyse des évolutions des types d'incidents
- **Clustering par cause racine** : Identification automatique des causes sous-jacentes

### 4.3.4 Résultats et optimisation des processus

**Performances techniques** :
- Précision de classification : 87% (amélioration de 40% par rapport à l'approche manuelle)
- Identification automatique de 15 nouvelles catégories de root cause
- Réduction de 50% du temps de traitement des tickets

**Impact organisationnel** :
- Optimisation de la répartition des charges entre équipes
- Amélioration de la traçabilité des résolutions
- Détection proactive des problèmes systémiques

## 4.4 Solution AppOps 360 : approche transverse et data-driven

### 4.4.1 Vision et objectifs stratégiques

La solution AppOps 360 s'inscrit dans une démarche d'amélioration continue et de capitalisation des bonnes pratiques au sein du cluster BPCR. L'objectif était de développer une approche data-driven pour offrir une vision à 360° des enjeux transverses, permettant de :
- Capitaliser sur les bonnes pratiques identifiées
- Capter les difficultés rencontrées par les équipes
- Optimiser les sollicitations des équipes AppOps
- Faciliter la prise de décision stratégique

### 4.4.2 Architecture data et méthodologie

**Approche transverse** :
La solution intègre des données provenant de multiples sources :
- Métriques techniques des applications
- Indicateurs de performance des équipes
- Retours d'expérience des projets
- Données de satisfaction des utilisateurs internes

**Architecture technique** :
- **Collecte** : Connecteurs vers les différents référentiels du cluster
- **Intégration** : ETL unifié pour harmoniser les données hétérogènes
- **Analyse** : Modèles de corrélation et d'analyse prédictive
- **Visualisation** : Dashboards interactifs pour différents niveaux de management

### 4.4.3 Impact et enseignements

**Valeur ajoutée** :
- Vision unifiée des enjeux du cluster BPCR
- Identification de synergies entre équipes
- Optimisation des ressources et des processus
- Amélioration de la communication transverse

## 4.5 Refonte des outils de gestion d'obsolescence technique

### 4.5.1 Contexte et enjeux

La gestion de l'obsolescence technique représente un défi majeur pour maintenir la sécurité et la performance des systèmes d'information. L'outillage existant nécessitait une modernisation pour répondre aux exigences croissantes de traçabilité et d'anticipation.

### 4.5.2 Solutions développées

**Conception du datawarehouse** :
- Architecture SQL optimisée pour l'analyse des données d'obsolescence
- Modèles de données normalisés pour garantir la cohérence
- Performances optimisées pour les requêtes complexes

**Interface ObsoWatch** :
- Dashboards Power BI pour la visualisation des indicateurs
- Alertes automatiques sur les seuils critiques
- Rapports automatisés pour les comités de pilotage

**IHM opérationnelle** :
- Interface utilisateur intuitive pour la gestion quotidienne
- Workflows automatisés pour les processus de validation
- Intégration avec les outils existants

### 4.5.3 Résultats et impact

**Gains opérationnels** :
- Réduction de 60% du temps de génération des rapports
- Amélioration de la traçabilité des décisions
- Anticipation renforcée des actions correctives

## 4.6 Évolution vers l'IA générative et les LLM

### 4.6.1 Exploration des nouvelles technologies

L'émergence de l'IA générative a ouvert de nouvelles perspectives d'innovation. Mon rôle a évolué vers l'exploration et l'implémentation de ces technologies avancées :

**Domaines d'application** :
- Analyse automatisée de documents techniques
- Génération de rapports et synthèses
- Assistance à la décision basée sur l'analyse sémantique
- Amélioration de l'expérience utilisateur

### 4.6.2 Implémentation et résultats

**Technologies maîtrisées** :
- LangChain pour le développement d'applications LLM
- Techniques RAG (Retrieval-Augmented Generation)
- Fine-tuning de modèles pour des cas d'usage spécifiques
- Intégration avec les systèmes existants

**Résultats probants** :
- Amélioration de 40% de la qualité des analyses documentaires
- Réduction significative du temps de traitement
- Enrichissement des capacités d'analyse existantes

## 4.7 Acculturation et formation des équipes

### 4.7.1 Rôle d'évangélisation

Au-delà des projets techniques, mon rôle s'est étendu à l'accompagnement organisationnel :

**Activités de formation** :
- Sessions de sensibilisation aux enjeux de l'IA
- Formation technique sur les outils et méthodologies
- Accompagnement personnalisé des équipes
- Rédaction de documentation et guides pratiques

### 4.7.2 Impact sur la culture organisationnelle

**Transformation observée** :
- Montée en compétences générale sur les sujets data
- Évolution des processus de travail
- Adoption progressive des outils et méthodes IA
- Développement d'une culture data-driven

**Mesures d'impact** :
- Augmentation du nombre d'équipes utilisant des solutions IA
- Amélioration des indicateurs de maturité technique
- Retours positifs sur l'accompagnement fourni

## 4.8 Synthèse et vision d'ensemble

### 4.8.1 Cohérence des projets

L'ensemble des projets réalisés s'inscrit dans une logique de transformation progressive :
- **Phase exploratoire** : Capacity planning et premiers modèles
- **Phase d'expansion** : Diversification des cas d'usage
- **Phase de maturité** : Solutions complexes et accompagnement organisationnel

### 4.8.2 Apport technique et organisationnel

**Dimension technique** :
- Maîtrise de l'ensemble de la chaîne MLOps
- Expertise sur diverses techniques d'IA (ML, NLP, IA générative)
- Capacité de déploiement et d'industrialisation

**Dimension organisationnelle** :
- Rôle de catalyseur dans l'adoption de l'IA
- Contribution à la transformation culturelle
- Impact sur la stratégie technologique du cluster

Cette diversité de projets illustre parfaitement la progression d'une organisation traditionnelle vers la maturité IA, thématique centrale de la réflexion développée dans la seconde partie de ce mémoire.


__________________________________________
# 5. RÉSULTATS OBTENUS ET CONCLUSIONS

## 5.1 Bilan quantitatif des réalisations

### 5.1.1 Livrables techniques produits

Au terme de cette mission d'alternance, le bilan quantitatif des réalisations dépasse largement les objectifs initiaux fixés :

**Solutions IA déployées en production** :
- **8 modèles de machine learning** industrialisés et opérationnels
- **4 pipelines MLOps** complètes avec monitoring automatisé
- **12 tableaux de bord** stratégiques utilisés par les équipes de direction
- **3 architectures data** robustes pour différents cas d'usage

**Couverture fonctionnelle** :
- **Capacity planning** : Automatisation de 80% des processus de prévision
- **Analyse de verbatims** : Traitement automatisé de 100% des retours clients IRC Flash
- **Classification de tickets** : Catégorisation automatique de 95% des incidents Métis
- **Gestion d'obsolescence** : Modernisation complète de l'outillage existant

**Performance technique** :
- **Réduction de 30%** de l'erreur de prévision en capacity planning
- **Amélioration de 70%** du temps d'analyse des verbatims clients
- **Gain de 50%** sur le temps de traitement des tickets incidents
- **Diminution de 60%** du temps de génération des rapports d'obsolescence

### 5.1.2 Technologies et outils maîtrisés

**Stack technologique étendu** :
- **Langages** : Python, SQL, JavaScript, Shell scripting
- **Frameworks ML** : TensorFlow, Scikit-learn, Hugging Face Transformers
- **Orchestration** : Apache Airflow, Kubernetes, Docker
- **Monitoring** : MLflow, Grafana, Elasticsearch
- **Cloud et DevOps** : AWS, GitLab CI/CD, ArgoCD

**Méthodologies adoptées** :
- **MLOps** : Industrialisation complète des cycles de vie des modèles
- **DevOps** : Intégration continue et déploiement automatisé
- **Agile** : Gestion de projet en sprints avec adaptation continue

### 5.1.3 Impact sur la productivité

**Gains de temps mesurés** :
- **Capacity planning** : 15 heures/semaine libérées pour l'analyse stratégique
- **Analyse verbatims** : 25 heures/semaine d'automatisation des tâches répétitives
- **Traitement tickets** : 30% d'amélioration de la réactivité de résolution
- **Reporting** : Génération automatisée de 80% des rapports mensuels

**Amélioration de la qualité** :
- **Standardisation** des processus d'analyse
- **Réduction des erreurs** grâce à l'automatisation
- **Traçabilité** renforcée des décisions
- **Reproductibilité** des analyses

## 5.2 Impact organisationnel et évolution de la culture IA

### 5.2.1 Transformation culturelle observée

**Évolution des mentalités** :
L'impact le plus significatif de cette mission réside dans la transformation culturelle observée au sein du cluster BPCR. Plusieurs indicateurs témoignent de cette évolution :

- **Adoption progressive** : Passage de 1 équipe utilisant des solutions IA à 8 équipes impliquées
- **Demandes spontanées** : Multiplication par 5 des sollicitations pour des projets IA
- **Formation continue** : 45 collaborateurs formés aux outils et concepts data science
- **Investissements** : Commande de serveurs dédiés IA suite aux premiers succès

**Changement de perception** :
L'intelligence artificielle est passée du statut de "technologie expérimentale" à celui d'"outil stratégique". Cette évolution se manifeste par :
- **Intégration** dans les processus de décision stratégique
- **Budgets dédiés** pour l'innovation IA
- **Reconnaissance institutionnelle** des apports de l'IA

### 5.2.2 Structuration des compétences

**Montée en compétences collective** :
- **Sensibilisation** : 100% des équipes du cluster sensibilisées aux enjeux IA
- **Formation technique** : 30% des développeurs formés aux outils MLOps
- **Expertise spécialisée** : Constitution d'un pool de 5 experts data science
- **Documentation** : Création d'une base de connaissances de 50+ documents techniques

**Évolution des rôles** :
- **Émergence** de nouveaux profils techniques (ML Engineer, Data Scientist)
- **Évolution** des fiches de poste existantes intégrant les compétences IA
- **Création** de nouvelles responsabilités (pilotage de projets IA)

### 5.2.3 Impact sur l'organisation du travail

**Nouveaux processus** :
- **Méthodologies** : Adoption des pratiques MLOps dans 60% des projets
- **Gouvernance** : Mise en place de comités de validation des modèles IA
- **Collaboration** : Renforcement des liens entre équipes techniques et métiers

**Amélioration de l'efficacité** :
- **Automatisation** : 40% de tâches répétitives automatisées
- **Aide à la décision** : 100% des comités mensuels équipés de dashboards IA
- **Proactivité** : Passage d'une approche réactive à une approche prédictive

## 5.3 Retour d'expérience sur la démarche adoptée

### 5.3.1 Facteurs clés de succès identifiés

**Approche progressive** :
La stratégie adoptée s'est révélée particulièrement efficace grâce à plusieurs facteurs :

- **Démarrage sur des cas d'usage concrets** : Le choix du capacity planning comme premier projet a permis de démontrer rapidement la valeur ajoutée
- **Résultats tangibles** : Chaque projet a apporté des gains mesurables, facilitant l'acceptation des suivants
- **Accompagnement humain** : L'accent mis sur la formation et l'accompagnement a réduit les résistances

**Collaboration étroite avec les métiers** :
- **Co-construction** : Implication systématique des utilisateurs finaux dans la conception
- **Feedback continu** : Boucles de rétroaction courtes pour ajuster les solutions
- **Appropriation** : Transfert de connaissances permettant l'autonomie des équipes

### 5.3.2 Défis rencontrés et solutions adoptées

**Défis techniques** :
- **Complexité des données** : Hétérogénéité des sources et qualité variable
  - *Solution* : Développement d'une couche d'abstraction et de nettoyage robuste
- **Contraintes sécuritaires** : Exigences strictes du secteur bancaire
  - *Solution* : Intégration native des bonnes pratiques de sécurité dans les architectures

**Défis organisationnels** :
- **Résistance au changement** : Appréhensions face aux nouvelles technologies
  - *Solution* : Approche pédagogique et démonstrations concrètes
- **Compétences techniques** : Écart entre les besoins et les compétences disponibles
  - *Solution* : Programme de formation continue et accompagnement personnalisé

### 5.3.3 Leçons apprises et bonnes pratiques

**Enseignements stratégiques** :
- **L'importance du sponsor** : Le soutien du management est crucial pour la réussite
- **La valeur de l'évangélisation** : L'accompagnement humain est aussi important que la technique
- **La nécessité de la mesure** : Quantifier les résultats facilite l'adoption et la pérennisation

**Bonnes pratiques développées** :
- **Documentation systématique** : Capitalisation des connaissances pour faciliter les transferts
- **Monitoring continu** : Surveillance des performances pour maintenir la qualité
- **Approche itérative** : Amélioration continue basée sur les retours d'expérience

### 5.3.4 Reproductibilité de l'approche

**Modèle transférable** :
L'approche développée présente des caractéristiques qui facilitent sa reproduction :
- **Méthodologie structurée** : Processus documenté et reproductible
- **Outils standardisés** : Stack technologique éprouvé et portable
- **Accompagnement formalisé** : Méthodes d'acculturation systématisées

**Adaptabilité** :
- **Flexibilité** : Capacité d'adaptation aux spécificités organisationnelles
- **Scalabilité** : Montée en charge progressive possible
- **Modularité** : Possibilité d'implémenter partiellement selon les besoins

## 5.4 Perspectives et recommandations

### 5.4.1 Évolution future envisagée

**Axes de développement** :
- **Expansion** : Extension des solutions IA à d'autres équipes du Crédit Agricole
- **Approfondissement** : Développement de cas d'usage plus complexes
- **Innovation** : Exploration de technologies émergentes (IA générative, Edge AI)

**Consolidation** :
- **Standardisation** : Harmonisation des pratiques et outils
- **Expertise** : Renforcement des compétences internes
- **Gouvernance** : Structuration de l'organisation autour de l'IA

### 5.4.2 Recommandations pour la suite

**Actions prioritaires** :
1. **Formalisation** de la stratégie IA du cluster
2. **Structuration** d'une équipe dédiée IA/Data Science
3. **Investissement** dans la formation continue
4. **Développement** d'un centre d'excellence IA

**Facteurs critiques** :
- **Maintien** de l'engagement du management
- **Pérennisation** des compétences développées
- **Adaptation** aux évolutions technologiques

## 5.5 Conclusion de la première partie

Cette mission d'alternance a largement dépassé les objectifs initiaux, tant sur le plan technique qu'organisationnel. Les résultats obtenus démontrent qu'une approche progressive et accompagnée permet d'introduire avec succès l'intelligence artificielle dans un environnement organisationnel traditionnel.

**Apports principaux** :
- **Technique** : Industrialisation de 8 solutions IA opérationnelles
- **Organisationnel** : Transformation culturelle d'un cluster de 200+ personnes
- **Méthodologique** : Développement d'une approche reproductible d'adoption de l'IA

**Enseignements majeurs** :
- L'importance de l'accompagnement humain dans la transformation technologique
- La nécessité d'une approche progressive pour faciliter l'adoption
- La valeur stratégique de la formation et de l'acculturation

Cette expérience soulève des questions fondamentales sur les mécanismes de transformation des organisations traditionnelles face aux nouvelles technologies. C'est cette problématique que nous explorons dans la seconde partie de ce mémoire, en analysant comment structurer efficacement la montée en maturité IA d'une organisation traditionnelle.

La transition opérée au sein du cluster BPCR constitue un cas d'étude particulièrement riche pour comprendre les enjeux, les défis et les facteurs clés de succès d'une telle transformation. Elle illustre concrètement le passage "de l'expérimentation à l'industrialisation" qui caractérise l'évolution vers la maturité IA.
