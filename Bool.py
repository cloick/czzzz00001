# Imports nÃ©cessaires
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import classification_report, confusion_matrix
import pandas as pd
import numpy as np

print("=== MODÃˆLE BASELINE - RANDOM FOREST ===\n")

# VÃ©rifier qu'on a bien tout en numÃ©rique
print(f"ğŸ“Š DONNÃ‰ES PRÃŠTES:")
print(f"X_train_simple shape: {X_train_simple.shape}")
print(f"X_test_simple shape: {X_test_simple.shape}")
print(f"Types non-numÃ©riques train: {X_train_simple.select_dtypes(exclude=[np.number]).shape[1]}")
print(f"Types non-numÃ©riques test: {X_test_simple.select_dtypes(exclude=[np.number]).shape[1]}")

# Distribution des classes
print(f"\nğŸ“ˆ DISTRIBUTION DES CLASSES:")
print("Train:")
print(y_train.value_counts(normalize=True).round(3))
print("Test:")  
print(y_test.value_counts(normalize=True).round(3))ğŸ¯ ENTRAÃNEMENT DU MODÃˆLE :# 1. ENTRAÃNEMENT RANDOM FOREST
print("\nğŸ¤– ENTRAÃNEMENT RANDOM FOREST...")

# ModÃ¨le simple avec paramÃ¨tres basiques
rf_model = RandomForestClassifier(
    n_estimators=100,        # 100 arbres
    max_depth=10,           # Profondeur limitÃ©e pour Ã©viter overfitting
    min_samples_split=50,   # Minimum Ã©chantillons pour split
    min_samples_leaf=20,    # Minimum Ã©chantillons par feuille
    random_state=42,        # ReproductibilitÃ©
    class_weight='balanced', # GÃ©rer dÃ©sÃ©quilibre des classes
    n_jobs=-1              # Utiliser tous les CPU
)

# Fit sur les donnÃ©es d'entraÃ®nement
rf_model.fit(X_train_simple, y_train)
print("âœ… ModÃ¨le entraÃ®nÃ© !")

# 2. PRÃ‰DICTIONS
print("\nğŸ”® PRÃ‰DICTIONS...")
y_pred_train = rf_model.predict(X_train_simple)
y_pred_test = rf_model.predict(X_test_simple)

# ProbabilitÃ©s pour analyse
y_pred_proba_test = rf_model.predict_proba(X_test_simple)
print("âœ… PrÃ©dictions gÃ©nÃ©rÃ©es !")ğŸ“Š Ã‰VALUATION MULTI-CLASSES :# 3. MÃ‰TRIQUES MULTI-CLASSES
print("\n=== Ã‰VALUATION MULTI-CLASSES ===")

# Accuracy
train_accuracy = accuracy_score(y_train, y_pred_train)
test_accuracy = accuracy_score(y_test, y_pred_test)

print(f"ğŸ¯ ACCURACY:")
print(f"  Train: {train_accuracy:.4f}")
print(f"  Test:  {test_accuracy:.4f}")
print(f"  Ã‰cart: {abs(train_accuracy - test_accuracy):.4f}")

# MÃ©triques dÃ©taillÃ©es (macro average pour classes dÃ©sÃ©quilibrÃ©es)
test_precision_macro = precision_score(y_test, y_pred_test, average='macro', zero_division=0)
test_recall_macro = recall_score(y_test, y_pred_test, average='macro', zero_division=0)
test_f1_macro = f1_score(y_test, y_pred_test, average='macro', zero_division=0)

print(f"\nğŸ“Š MÃ‰TRIQUES MACRO (Ã©galitÃ© entre classes):")
print(f"  Precision: {test_precision_macro:.4f}")
print(f"  Recall:    {test_recall_macro:.4f}")
print(f"  F1-Score:  {test_f1_macro:.4f}")

# MÃ©triques pondÃ©rÃ©es (par support de classe)
test_precision_weighted = precision_score(y_test, y_pred_test, average='weighted', zero_division=0)
test_recall_weighted = recall_score(y_test, y_pred_test, average='weighted', zero_division=0)
test_f1_weighted = f1_score(y_test, y_pred_test, average='weighted', zero_division=0)

print(f"\nâš–ï¸ MÃ‰TRIQUES WEIGHTED (pondÃ©rÃ©es par classe):")
print(f"  Precision: {test_precision_weighted:.4f}")
print(f"  Recall:    {test_recall_weighted:.4f}")
print(f"  F1-Score:  {test_f1_weighted:.4f}")

# Rapport dÃ©taillÃ© par classe
print(f"\nğŸ“‹ CLASSIFICATION REPORT:")
print(classification_report(y_test, y_pred_test))ğŸ¯ Ã‰VALUATION BINAIRE (SuccÃ¨s vs ProblÃ¨me) :# 4. Ã‰VALUATION BINAIRE - Plus business-friendly
print("\n=== Ã‰VALUATION BINAIRE (SUCCÃˆS vs PROBLÃˆME) ===")

# CrÃ©er target binaire
y_test_binary = (y_test == 'SuccÃ¨s').astype(int)
y_pred_binary = (y_pred_test == 'SuccÃ¨s').astype(int)

# MÃ©triques binaires
binary_accuracy = accuracy_score(y_test_binary, y_pred_binary)
binary_precision = precision_score(y_test_binary, y_pred_binary)
binary_recall = recall_score(y_test_binary, y_pred_binary)
binary_f1 = f1_score(y_test_binary, y_pred_binary)

print(f"ğŸ¯ SUCCÃˆS vs PROBLÃˆME:")
print(f"  Accuracy:  {binary_accuracy:.4f}")
print(f"  Precision: {binary_precision:.4f} (des prÃ©dictions 'SuccÃ¨s', combien sont vraies)")
print(f"  Recall:    {binary_recall:.4f} (des vrais 'SuccÃ¨s', combien dÃ©tectÃ©s)")
print(f"  F1-Score:  {binary_f1:.4f}")

# Matrice de confusion binaire
print(f"\nğŸ“Š MATRICE DE CONFUSION BINAIRE:")
conf_matrix_binary = confusion_matrix(y_test_binary, y_pred_binary)
print("           Pred_ProblÃ¨me  Pred_SuccÃ¨s")
print(f"Vrai_ProblÃ¨me      {conf_matrix_binary[0,0]:4d}        {conf_matrix_binary[0,1]:4d}")
print(f"Vrai_SuccÃ¨s        {conf_matrix_binary[1,0]:4d}        {conf_matrix_binary[1,1]:4d}")ğŸ” FEATURE IMPORTANCES :# 5. VARIABLES LES PLUS IMPORTANTES
print("\n=== TOP 10 VARIABLES IMPORTANTES ===")

# RÃ©cupÃ©rer importances
feature_names = X_train_simple.columns
importances = rf_model.feature_importances_

# CrÃ©er DataFrame et trier
feature_importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': importances
}).sort_values('importance', ascending=False)

print("ğŸ† TOP 10 FEATURES:")
for i, row in feature_importance_df.head(10).iterrows():
    print(f"{row['feature']:30s} | {row['importance']:.4f}")

print(f"\nâœ… MODÃˆLE BASELINE Ã‰VALUÃ‰ !")
