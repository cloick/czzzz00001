L'utilisateur a une erreur NameError pour 'X_train_del'. En regardant le code que j'ai fourni, je vois que j'ai utilis√© X_train_sel et X_test_sel dans la fonction debug, mais il se peut que ces variables ne soient pas d√©finies dans le scope global ou qu'il y ait une typo.

Je dois corriger la fonction debug en m'assurant que:
1. J'utilise les bonnes variables 
2. Je refais le preprocessing si n√©cessaire
3. Je corrige toute erreur de typo

Je vois que dans les fonctions pr√©c√©dentes, nous utilisions X_train_sel et X_test_sel apr√®s le SelectKBest. Il faut que je m'assure que ces variables sont bien d√©finies ou que je les recr√©e dans la fonction debug.

**Ah ! Erreur de variable.** Voici la version corrig√©e avec le preprocessing inclus :

```python
def debug_threshold_inconsistency():
    """Identifier l'origine de l'incoh√©rence - Version corrig√©e"""
    
    # === REFAIRE LE PREPROCESSING POUR √äTRE S√õR ===
    from sklearn.feature_selection import SelectKBest, f_classif
    from sklearn.metrics import confusion_matrix, classification_report
    import numpy as np
    
    selector = SelectKBest(score_func=f_classif, k=5)
    X_train_selected = selector.fit_transform(X_train, y_train)
    X_test_selected = selector.transform(X_test)
    
    selected_features = X_train.columns[selector.get_support()]
    X_train_sel = pd.DataFrame(X_train_selected, columns=selected_features)
    X_test_sel = pd.DataFrame(X_test_selected, columns=selected_features)
    
    print(f"Features s√©lectionn√©es: {list(selected_features)}")
    print(f"Shape train: {X_train_sel.shape}, Shape test: {X_test_sel.shape}")
    
    # 1. V√âRIFIER LE MOD√àLE UTILIS√â
    print("\n=== V√âRIFICATION DU MOD√àLE ===")
    model = bayesian_models['LogisticRegression']  # Mod√®le optimis√©
    print(f"Param√®tres du mod√®le: {model.get_params()}")
    
    # 2. REPRODUIRE LE R√âSULTAT D'OPTIMISATION
    print("\n=== ENTRA√éNEMENT ET PR√âDICTION ===")
    model.fit(X_train_sel, y_train)
    y_pred_default = model.predict(X_test_sel)
    
    cm_default = confusion_matrix(y_test, y_pred_default)
    print(f"Matrice confusion predict() d√©faut: \n{cm_default}")
    
    # 3. V√âRIFIER LES M√âTRIQUES AVEC SEUIL 0.5 MANUEL
    print("\n=== PR√âDICTION AVEC SEUIL 0.5 MANUEL ===")
    y_proba = model.predict_proba(X_test_sel)
    print(f"Shape probabilit√©s: {y_proba.shape}")
    print(f"Premiers exemples proba: \n{y_proba[:5]}")
    
    # Proba de la classe 0 (probl√®me)
    y_proba_probleme = y_proba[:, 0]  
    y_pred_05 = (y_proba_probleme >= 0.5).astype(int)
    
    cm_05 = confusion_matrix(y_test, y_pred_05)
    print(f"Matrice confusion seuil 0.5 manuel: \n{cm_05}")
    
    # 4. CALCULER M√âTRIQUES DES DEUX FA√áONS
    print("\n=== M√âTRIQUES PREDICT() DEFAULT ===")
    print(classification_report(y_test, y_pred_default))
    
    print("\n=== M√âTRIQUES SEUIL 0.5 MANUEL ===")
    print(classification_report(y_test, y_pred_05))
    
    # 5. V√âRIFIER SI M√äME R√âSULTAT
    are_same = np.array_equal(y_pred_default, y_pred_05)
    print(f"\n=== COMPARAISON ===")
    print(f"Pr√©dictions identiques: {are_same}")
    
    if not are_same:
        diff_count = np.sum(y_pred_default != y_pred_05)
        print(f"Nombre de diff√©rences: {diff_count}")
        
        # Analyser les diff√©rences
        print(f"D√©faut - 0: {np.sum(y_pred_default == 0)}, 1: {np.sum(y_pred_default == 1)}")
        print(f"Manuel - 0: {np.sum(y_pred_05 == 0)}, 1: {np.sum(y_pred_05 == 1)}")
    
    # 6. CALCULER MANUELLEMENT LES M√âTRIQUES COMME DANS L'OPTIMISATION
    print("\n=== CALCUL MANUEL M√âTRIQUES (STYLE OPTIMISATION) ===")
    tn, fp, fn, tp = cm_default.ravel()
    
    # M√©triques pour classe 0 (probl√®me)
    recall_probleme = tn / (tn + fp) if (tn + fp) > 0 else 0
    precision_probleme = tn / (tn + fn) if (tn + fn) > 0 else 0
    fausses_alertes = fn
    
    print(f"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}")
    print(f"Recall probl√®me: {recall_probleme:.4f}")
    print(f"Precision probl√®me: {precision_probleme:.4f}")  
    print(f"Fausses alertes: {fausses_alertes}")
    
    return model, y_pred_default, y_pred_05, y_proba

# Lancer le debug
print("üîç DEBUG DE L'INCOH√âRENCE")
model, pred_default, pred_05, proba = debug_threshold_inconsistency()
```

**Cette version :**
1. **Recr√©e le preprocessing** pour √©viter les erreurs de variables
2. **Compare predict() vs seuil manuel**
3. **Affiche les matrices de confusion** des deux m√©thodes
4. **Calcule manuellement** les m√©triques comme dans l'optimisation

**Lancez √ßa et on va identifier d'o√π vient l'incoh√©rence !** üîç
